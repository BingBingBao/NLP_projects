{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project: Movie Reviews Sentiment Analysis**\n",
    "\n",
    "This project focuses on sentiment analysis of movie reviews, aiming to classify them as positive or negative based on textual content. \n",
    "\n",
    "The primary objective is to explore and compare the effectiveness of various deep learning models (CNN vs. RNN) for text classification.\n",
    "\n",
    "**Models**\n",
    "\n",
    "- Convolutional Neural Networks (CNNs): \n",
    "\n",
    "- Recurrent Neural Networks (RNNs):\n",
    "   - GRU (Gated Recurrent Units): For capturing sequential patterns with fewer parameters.\n",
    "   - LSTM (Long Short-Term Memory): To capture long-term dependencies in text.\n",
    "   - Stacked LSTM: to enhance the learning of hierarchical patterns.\n",
    "\n",
    "**Model Comparison**\n",
    "\n",
    "Provides insights into the strengths and limitations of different models, especially in handling long and complex text sequences.\n",
    "\n",
    "- Convolutional Neural Networks (CNNs) are a type of deep learning model primarily designed for image-related tasks (capture spatial features), while Recurrent Neural Networks (RNNs) are designed to process sequential data, making them ideal for time series, natural language processing (NLP), and any data where the order of the data points matters (like text).\n",
    "\n",
    "- But, in this project, the three-layer CNN model achieved the best performance, with an accuracy of 91%. \n",
    "\n",
    "- Possible reasons:\n",
    "\n",
    "    -  CNN outperforms RNNs (like LSTMs or GRUs) here could be closely tied to the nature of the task: **binary sentiment classification (positive or negative).**\n",
    "    \n",
    "    -  Sentiment analysis often relies on **local patterns**:\n",
    "\n",
    "        Sentiment is usually determined by the presence of specific keywords or short phrases (e.g., \"not good,\" \"absolutely amazing\").\n",
    "\n",
    "        CNNs, with their convolutional filters, are exceptionally good at identifying such n-gram patterns.\n",
    "        \n",
    "        RNNs process the entire sequence, which can dilute the impact of strong local signals in favor of modeling the overall sequence structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import  re\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import tqdm\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten, Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, GRU\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# fix random seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bingh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\bingh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bingh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 21 10:17:01 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   36C    P8             11W /  200W |     753MiB /  12282MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3256    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A      5748    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A      6004    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A      7432    C+G   ...n\\131.0.2903.146\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     11148    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     11476    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     13244    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
      "|    0   N/A  N/A     13752    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13976    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14000    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     17348    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     20192    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     20600    C+G   ...n\\131.0.2903.146\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     22320    C+G   ...951_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A     23944    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     25288    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     28304    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "GPUs Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/movie_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Train and Text Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data['review'].values\n",
    "sentiments = data['sentiment'].values\n",
    "\n",
    "train_review, test_review = np.split(reviews, [35000])\n",
    "train_sentiment, test_sentiment = np.split(sentiments, [35000])\n",
    "\n",
    "# or otherways:\n",
    "# train_review = reviews[:3500]\n",
    "# test_review = reviews[3500:]\n",
    "\n",
    "# train_sentiment = sentiments[:3500]\n",
    "# test_sentiment = sentiments[3500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000,), (15000,), (35000,), (15000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_review.shape, test_review.shape, train_sentiment.shape, test_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\",\n",
       "       'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.',\n",
       "       'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.',\n",
       "       \"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\",\n",
       "       'Petter Mattei\\'s \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler\\'s play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei\\'s direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_review[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "\n",
    "The text preprocessing efforts focus on:\n",
    "- Cleaning: Removing HTML tags, scripts, special characters, and accents.\n",
    "- Normalization: Ensuring uniform case, spacing, and expanded contractions.\n",
    "- Preparation: Producing clean, plain text for better performance in NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "  soup = BeautifulSoup(text, \"html.parser\")\n",
    "  [s.extract() for s in soup(['iframe', 'script'])]\n",
    "  stripped_text = soup.get_text()\n",
    "  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "  return stripped_text\n",
    "\n",
    "def remove_accented_chars(text): # á -> a\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "  return text\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "  norm_docs = []\n",
    "  for doc in tqdm.tqdm(docs):\n",
    "    doc = strip_html_tags(doc)\n",
    "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    doc = doc.lower()\n",
    "    doc = remove_accented_chars(doc)\n",
    "    doc = contractions.fix(doc)\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, flags=re.I|re.A)\n",
    "    doc = re.sub(' +', ' ', doc)\n",
    "    doc = doc.strip()\n",
    "    norm_docs.append(doc)\n",
    "\n",
    "  return norm_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 455/35000 [00:00<00:07, 4521.78it/s]C:\\Users\\bingh\\AppData\\Local\\Temp\\ipykernel_22176\\3120417334.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n",
      "100%|██████████| 35000/35000 [00:07<00:00, 4721.09it/s]\n",
      "100%|██████████| 15000/15000 [00:03<00:00, 4698.25it/s]\n"
     ]
    }
   ],
   "source": [
    "train_review_normalized = pre_process_corpus(train_review)\n",
    "test_review_normalized = pre_process_corpus(test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one of the other reviewers has mentioned that after watching just 1 oz episode you will be hooked they are right as this is exactly what happened with methe first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordit is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda them city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awayi would say the main appeal of the show is due to the fact that it goes where other shows would not dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz does not mess around the first episode i ever saw struck me as so nasty it was surreal i could not say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards who will be sold out for a nickel inmates who will kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthat is if you can get in touch with your darker side',\n",
       " 'a wonderful little production the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done',\n",
       " 'i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a lighthearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to lovethis was the most i would laughed at one of woodys comedies in years dare i say a decade while i have never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young womanthis may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman a great comedy to go see with friends',\n",
       " 'basically there is a family where a little boy jake thinks there is a zombie in his closet his parents are fighting all the timethis movie is slower than a soap opera and suddenly jake decides to become rambo and kill the zombieok first of all when you are going to make a film you must decide if its a thriller or a drama as a drama the movie is watchable parents are divorcing arguing like in real life and then we have jake with his closet which totally ruins all the film i expected to see a boogeyman similar movie and instead i watched a drama with some meaningless thriller spots3 out of 10 just for the well playing parents descent dialogs as for the shots with jake just ignore them',\n",
       " 'petter matteis love in the time of money is a visually stunning film to watch mr mattei offers us a vivid portrait about human relations this is a movie that seems to be telling us what money power and success do to people in the different situations we encounter this being a variation on the arthur schnitzlers play about the same theme the director transfers the action to the present time new york where all these different characters meet and connect each one is connected in one way or another to the next person but no one seems to know the previous point of contact stylishly the film has a sophisticated luxurious look we are taken to see how these people live and the world they live in their own habitatthe only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits a big city is not exactly the best place in which human relations find sincere fulfillment as one discerns is the case with most of the people we encounterthe acting is good under mr matteis direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier and the rest of the talented cast make these characters come alivewe wish mr mattei good luck and await anxiously for his next work']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_review_normalized[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization (X)\n",
    "\n",
    "Tokenization\n",
    "\n",
    "Tokenization is the process of splitting text into smaller units, typically tokens, which can be words, subwords, or characters. For deep learning models, this process often includes mapping these tokens to numerical representations that can be processed by the model.\n",
    "\n",
    "Note: a Keras Tokenizer behaves like a \"trained model\" for text preprocessing, Once the tokenizer is fitted, it has a fixed vocabulary (word_index) and mapping between words and integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize the tokenizer with the <UNK> (unknown token)\n",
    "t = Tokenizer(oov_token='<UNK>')\n",
    "\n",
    "# 2. Fit the tokenizer only on the training reviews\n",
    "t.fit_on_texts(train_review_normalized)\n",
    "\n",
    "# 3. Convert text to sequences\n",
    "# Transform Both Training and Test Data Using the Same Tokenizer\n",
    "train_sequences = t.texts_to_sequences(train_review_normalized)\n",
    "test_sequences = t.texts_to_sequences(test_review_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=175812\n",
      "Number of Documents=35000\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
    "print(\"Number of Documents={}\".format(t.document_count))\n",
    "\n",
    "# Tokenizer detected 175812 unique words across all documents\n",
    "# Tokenizer was fitted on 3500 text documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2463"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(sentence_tokens) for sentence_tokens in train_sequences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of train sequence lengths\n",
    "\n",
    "Plot the sequence length\n",
    "\n",
    "This analysis helps determine how to handle sequence lengths for training a deep learning model, such as setting an appropriate maxlen for padding or truncation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bingh\\AppData\\Local\\Temp\\ipykernel_22176\\3383209453.py:14: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend(fontsize=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate lengths of sequences\n",
    "train_lens = [len(s) for s in train_sequences]\n",
    "\n",
    "mean_length = np.mean(train_lens)\n",
    "median_length = np.median(train_lens)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.hist(train_lens, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "ax.set_title('Distribution of Sequence Lengths in Train Reviews', fontsize=14)\n",
    "ax.set_xlabel('Sequence Length', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all reviews are of same length. To handle this difference in length of reviews, we define a maximum length. For reviews which are smaller than this length, we pad them with zeros which longer ones are truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 1000), (15000, 1000))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "\n",
    "# pad dataset to a maximum review length in words\n",
    "X_train = sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "X_test = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH,  padding='post')\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Labels (Y)\n",
    "\n",
    "The dataset contains labels of the form positive/negative. The following step encodes the labels using sklearn's LabelEncoder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "num_classes=2 # positive -> 1, negative -> 0\n",
    "\n",
    "y_train = le.fit_transform(train_sentiment)\n",
    "y_test = le.transform(test_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'positive' 'positive' 'negative' 'positive']\n",
      "--------------------------------------------------\n",
      "[1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_sentiment[:5])\n",
    "print(\"-\" * 50)\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'positive' 'negative' 'positive' 'positive']\n",
      "--------------------------------------------------\n",
      "[0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_sentiment[:5])\n",
    "print(\"-\" * 50)\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CNN Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the Model**\n",
    "\n",
    "Since textual data is a sequence of words, we utilize ```1D``` convolutions to scan through the sentences.\n",
    "The model first transforms each word into lower dimensional embedding/vector space followed by 1d convolutions and then passing the data through dense layers before the final layer for classification\n",
    "\n",
    "**Embeddings**\n",
    "\n",
    "The Embedding layer helps us generate the word embeddings from scratch. This layer\n",
    "is also initialized with some weights and is updated based on our optimizer, similar to\n",
    "weights on the neuron units in other layers when the network tries to minimize the loss\n",
    "in each epoch. Thus, the embedding layer tries to optimize its weights such that we get\n",
    "the best word embeddings that will generate minimum error in the model and capture\n",
    "semantic similarity and relationships among words. How do we get the embeddings?\n",
    "Let’s say we have a review with three terms ['movie', 'was', 'good'] and a vocab_map\n",
    "consisting of word to index mappings for 175860 words.\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "  <img src=\"https://i.imgur.com/wOPsWof.png\" alt=\"Image 1\" width=\"1000\">\n",
    "  <img src=\"https://i.imgur.com/XRaoZRW.png\" alt=\"Image 2\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175812"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the unique number of words in our training data is 175812\n",
    "VOCAB_SIZE = len(t.word_index)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 1000, 300)         52743900  \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 1000, 128)         153728    \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 500, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 500, 128)          0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 500, 64)           32832     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 250, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 250, 64)           0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 250, 32)           8224      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 125, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               1024256   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,963,197\n",
      "Trainable params: 53,963,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "VOCAB_SIZE = 175813\n",
    "EMBED_SIZE = 300\n",
    "MAX_SEQUENCE_LENGTH = 1000 \n",
    "\n",
    "# Create the model\n",
    "model_cnn = Sequential()\n",
    "\n",
    "# Embedding layer is of dim: 175813 x 300\n",
    "model_cnn.add(Embedding(input_dim=VOCAB_SIZE, output_dim=EMBED_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
    "\n",
    "# Convolutional and pooling layers\n",
    "model_cnn.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "model_cnn.add(Dropout(0.5))  # Regularization; avoid overfitting\n",
    "\n",
    "model_cnn.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "model_cnn.add(Dropout(0.5))  # Regularization; avoid overfitting\n",
    "\n",
    "model_cnn.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flattening the output\n",
    "model_cnn.add(Flatten())\n",
    "\n",
    "# Dense layers for classification\n",
    "model_cnn.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model_cnn.add(Dropout(0.5))  # Regularization\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "247/247 [==============================] - 18s 41ms/step - loss: 0.5516 - accuracy: 0.6544 - val_loss: 0.2733 - val_accuracy: 0.8966\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 10s 39ms/step - loss: 0.1983 - accuracy: 0.9239 - val_loss: 0.2437 - val_accuracy: 0.9037\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 10s 39ms/step - loss: 0.0638 - accuracy: 0.9780 - val_loss: 0.2970 - val_accuracy: 0.8963\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9931Restoring model weights from the end of the best epoch: 2.\n",
      "247/247 [==============================] - 10s 39ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.4470 - val_accuracy: 0.8711\n",
      "Epoch 4: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c739c9bc40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "# Early stop\n",
    "## using early stopping to prevent overfitting and ensure the best model weights are restored.\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                      patience = 2,\n",
    "                                      restore_best_weights = True,\n",
    "                                      verbose = 1)\n",
    "\n",
    "# Fit the model\n",
    "model_cnn.fit(X_train, y_train,\n",
    "          validation_split = 0.1,\n",
    "          epochs = EPOCHS,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          callbacks = [es],\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2394 - accuracy: 0.9085\n",
      "Accuracy: 90.85%\n"
     ]
    }
   ],
   "source": [
    "scores = model_cnn.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"Test Loss: %.2f%%\" % (scores[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_probas = model_cnn.predict(X_test).ravel()  # ravel(): latten an array into a one-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = [1 if proba > 0.5 else 0 for proba in predict_probas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'positive', 'positive'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_predictions = le.inverse_transform(y_predictions)\n",
    "sentiment_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91      7490\n",
      "    positive       0.91      0.91      0.91      7510\n",
      "\n",
      "    accuracy                           0.91     15000\n",
      "   macro avg       0.91      0.91      0.91     15000\n",
      "weighted avg       0.91      0.91      0.91     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6800</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>682</td>\n",
       "      <td>6828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      6800       690\n",
       "positive       682      6828"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiment, sentiment_predictions))\n",
    "pd.DataFrame(confusion_matrix(test_sentiment, sentiment_predictions), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LSTM Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**LSTM**\n",
    "\n",
    "LSTMs try to overcome the shortcomings of RNN models, especially with regard to handling long-term dependencies and problems that occur when the weight matrix associated with the units (neurons) become too small (leading to vanishing gradient) or too large (leading to exploding gradient). These architectures are more complex than regular deep networks and going into detailed internals and math concepts are out of the current scope, but we will try to cover the essentials here without making it math heavy\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "  <img src=\"https://i.imgur.com/c8qGKX8.png\" alt=\"Image 1\" width=\"1000\">\n",
    "  <img src=\"https://i.imgur.com/uiIbDk1.png\" alt=\"Image 2\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 1000, 300)         52743900  \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 256)              439296    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,249,245\n",
      "Trainable params: 53,249,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "EMBEDDING_DIM = 300 # word embedding size for each token\n",
    "LSTM_DIM = 128   # the number of hidden units in each LSTM cell i.e the hidden state embedding size\n",
    "# total LSTM cells = sequence length (num of tokens) i.e total number of words per document\n",
    "\n",
    "# Create the model\n",
    "model_lstm_1 = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model_lstm_1.add(Embedding(input_dim=VOCAB_SIZE,\n",
    "                           output_dim=EMBEDDING_DIM,\n",
    "                           input_length=MAX_SEQUENCE_LENGTH))\n",
    "# to use bidirectional lstms\n",
    "model_lstm_1.add(Bidirectional(LSTM(LSTM_DIM, return_sequences=False)))\n",
    "model_lstm_1.add(Dropout(0.5)) \n",
    "\n",
    "# Fully connected layers\n",
    "model_lstm_1.add(Dense(256, activation='relu'))\n",
    "model_lstm_1.add(Dropout(0.5)) \n",
    "model_lstm_1.add(Dense(1, activation=\"sigmoid\"))    \n",
    "\n",
    "# Compile the model\n",
    "model_lstm_1.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "247/247 [==============================] - 37s 143ms/step - loss: 0.5166 - accuracy: 0.7376 - val_loss: 0.4022 - val_accuracy: 0.8317\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 35s 142ms/step - loss: 0.2588 - accuracy: 0.9064 - val_loss: 0.3094 - val_accuracy: 0.8769\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 35s 143ms/step - loss: 0.1186 - accuracy: 0.9598 - val_loss: 0.4351 - val_accuracy: 0.8703\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9807Restoring model weights from the end of the best epoch: 2.\n",
      "247/247 [==============================] - 35s 143ms/step - loss: 0.0584 - accuracy: 0.9807 - val_loss: 0.4710 - val_accuracy: 0.8740\n",
      "Epoch 4: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb09fa22f0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Early stop\n",
    "## using early stopping to prevent overfitting and ensure the best model weights are restored.\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                      patience = 2,\n",
    "                                      restore_best_weights = True,\n",
    "                                      verbose = 1)\n",
    "\n",
    "# Fit the model\n",
    "model_lstm_1.fit(X_train, y_train,\n",
    "          validation_split = 0.1,\n",
    "          epochs = EPOCHS,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          callbacks = [es],\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 21s 44ms/step - loss: 0.3169 - accuracy: 0.8762\n",
      "Test Accuracy: 87.62%\n",
      "Test Loss: 31.69%\n"
     ]
    }
   ],
   "source": [
    "scores = model_lstm_1.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"Test Loss: %.2f%%\" % (scores[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 20s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_probas = model_lstm_1.predict(X_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = [1 if proba > 0.5 else 0 for proba in predict_probas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'positive', 'positive'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_predictions = le.inverse_transform(y_predictions)\n",
    "sentiment_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88      7490\n",
      "    positive       0.88      0.87      0.88      7510\n",
      "\n",
      "    accuracy                           0.88     15000\n",
      "   macro avg       0.88      0.88      0.88     15000\n",
      "weighted avg       0.88      0.88      0.88     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6630</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>997</td>\n",
       "      <td>6513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      6630       860\n",
       "positive       997      6513"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiment, sentiment_predictions))\n",
    "pd.DataFrame(confusion_matrix(test_sentiment, sentiment_predictions), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Stacked LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 1000, 300)         52743900  \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 1000, 256)        439296    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,643,485\n",
      "Trainable params: 53,643,485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "EMBEDDING_DIM = 300  # Word embedding size\n",
    "LSTM_DIM = 128       # Number of hidden units in each LSTM cell\n",
    "NUM_LAYERS = 2       # Number of LSTM layers\n",
    "\n",
    "# Create the model\n",
    "model_lstm_stacked = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model_lstm_stacked.add(Embedding(input_dim=VOCAB_SIZE,\n",
    "                                 output_dim=EMBEDDING_DIM,\n",
    "                                 input_length=MAX_SEQUENCE_LENGTH))\n",
    "\n",
    "# Stacked LSTM layers\n",
    "for i in range(NUM_LAYERS):\n",
    "    return_sequences = True if i < NUM_LAYERS - 1 else False\n",
    "    model_lstm_stacked.add(Bidirectional(LSTM(LSTM_DIM, return_sequences=return_sequences)))\n",
    "\n",
    "# Dropout for regularization\n",
    "model_lstm_stacked.add(Dropout(0.5))\n",
    "\n",
    "# Fully connected layers\n",
    "model_lstm_stacked.add(Dense(256, activation='relu'))\n",
    "model_lstm_stacked.add(Dropout(0.5))  \n",
    "model_lstm_stacked.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model_lstm_stacked.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_stacked.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "247/247 [==============================] - 70s 273ms/step - loss: 0.5462 - accuracy: 0.7303 - val_loss: 0.5343 - val_accuracy: 0.7406\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 67s 270ms/step - loss: 0.4676 - accuracy: 0.7874 - val_loss: 0.6973 - val_accuracy: 0.7417\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 69s 280ms/step - loss: 0.2222 - accuracy: 0.9212 - val_loss: 0.3351 - val_accuracy: 0.8623\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 68s 276ms/step - loss: 0.1229 - accuracy: 0.9601 - val_loss: 0.4061 - val_accuracy: 0.8637\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9753Restoring model weights from the end of the best epoch: 3.\n",
      "247/247 [==============================] - 69s 278ms/step - loss: 0.0794 - accuracy: 0.9753 - val_loss: 0.4356 - val_accuracy: 0.8689\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Early stop\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                      patience = 2,\n",
    "                                      restore_best_weights = True,\n",
    "                                      verbose = 1)\n",
    "\n",
    "# Fit the model\n",
    "history = model_lstm_stacked.fit(X_train, y_train,\n",
    "          validation_split = 0.1,\n",
    "          epochs = EPOCHS,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          callbacks = [es],\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 39s 83ms/step - loss: 0.3447 - accuracy: 0.8709\n",
      "Test Accuracy: 87.09%\n",
      "Test Loss: 34.47%\n"
     ]
    }
   ],
   "source": [
    "scores = model_lstm_stacked.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"Test Loss: %.2f%%\" % (scores[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 21s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_probas = model_lstm_1.predict(X_test).ravel()\n",
    "\n",
    "y_predictions = [1 if proba > 0.5 else 0 for proba in predict_probas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'positive', 'positive'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_predictions = le.inverse_transform(y_predictions)\n",
    "sentiment_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88      7490\n",
      "    positive       0.88      0.87      0.88      7510\n",
      "\n",
      "    accuracy                           0.88     15000\n",
      "   macro avg       0.88      0.88      0.88     15000\n",
      "weighted avg       0.88      0.88      0.88     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6630</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>997</td>\n",
       "      <td>6513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      6630       860\n",
       "positive       997      6513"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiment, sentiment_predictions))\n",
    "pd.DataFrame(confusion_matrix(test_sentiment, sentiment_predictions), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GRU Model** (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 1000, 300)         52743900  \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 256)              330240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,140,189\n",
      "Trainable params: 53,140,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "EMBEDDING_DIM = 300\n",
    "GRU_DIM = 128\n",
    "VOCAB_SIZE = 175813\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "\n",
    "# Create the model\n",
    "model_gru = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model_gru.add(Embedding(input_dim=VOCAB_SIZE,\n",
    "                        output_dim=EMBEDDING_DIM,\n",
    "                        input_length=MAX_SEQUENCE_LENGTH))\n",
    "\n",
    "# Bidirectional GRU\n",
    "model_gru.add(Bidirectional(GRU(GRU_DIM, return_sequences=False)))\n",
    "\n",
    "# Fully connected layers\n",
    "model_gru.add(Dense(256, activation='relu'))\n",
    "model_gru.add(Dropout(0.5))\n",
    "model_gru.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model_gru.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "247/247 [==============================] - 36s 139ms/step - loss: 0.4789 - accuracy: 0.7590 - val_loss: 0.3612 - val_accuracy: 0.8437\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 36s 146ms/step - loss: 0.2153 - accuracy: 0.9209 - val_loss: 0.3680 - val_accuracy: 0.8423\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9660Restoring model weights from the end of the best epoch: 1.\n",
      "247/247 [==============================] - 34s 139ms/step - loss: 0.1038 - accuracy: 0.9660 - val_loss: 0.3916 - val_accuracy: 0.8600\n",
      "Epoch 3: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb0b393d00>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Early stop\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                      patience = 2,\n",
    "                                      restore_best_weights = True,\n",
    "                                      verbose = 1)\n",
    "\n",
    "# Fit the model\n",
    "model_gru.fit(X_train, y_train,\n",
    "          validation_split = 0.1,\n",
    "          epochs = EPOCHS,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          callbacks = [es],\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 18s 37ms/step - loss: 0.3521 - accuracy: 0.8515\n",
      "Test Accuracy: 85.15%\n",
      "Test Loss: 35.21%\n"
     ]
    }
   ],
   "source": [
    "scores = model_gru.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"Test Loss: %.2f%%\" % (scores[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 20s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_probas = model_lstm_1.predict(X_test).ravel()\n",
    "\n",
    "y_predictions = [1 if proba > 0.5 else 0 for proba in predict_probas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'positive', 'positive'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_predictions = le.inverse_transform(y_predictions)\n",
    "sentiment_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87      7490\n",
      "    positive       0.85      0.90      0.87      7510\n",
      "\n",
      "    accuracy                           0.87     15000\n",
      "   macro avg       0.87      0.87      0.87     15000\n",
      "weighted avg       0.87      0.87      0.87     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6342</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>787</td>\n",
       "      <td>6723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      6342      1148\n",
       "positive       787      6723"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiment, sentiment_predictions))\n",
    "pd.DataFrame(confusion_matrix(test_sentiment, sentiment_predictions), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_sentiment_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_sentiment_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_cnn.save(\"cnn_sentiment_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
